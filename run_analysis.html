<!DOCTYPE html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>

<title>Getting and Cleaning Data Course Project</title>

<script type="text/javascript">
window.onload = function() {
  var imgs = document.getElementsByTagName('img'), i, img;
  for (i = 0; i < imgs.length; i++) {
    img = imgs[i];
    // center an image if it is the only element of its parent
    if (img.parentElement.childElementCount === 1)
      img.parentElement.style.textAlign = 'center';
  }
};
</script>

<!-- Styles for R syntax highlighter -->
<style type="text/css">
   pre .operator,
   pre .paren {
     color: rgb(104, 118, 135)
   }

   pre .literal {
     color: #990073
   }

   pre .number {
     color: #099;
   }

   pre .comment {
     color: #998;
     font-style: italic
   }

   pre .keyword {
     color: #900;
     font-weight: bold
   }

   pre .identifier {
     color: rgb(0, 0, 0);
   }

   pre .string {
     color: #d14;
   }
</style>

<!-- R syntax highlighter -->
<script type="text/javascript">
var hljs=new function(){function m(p){return p.replace(/&/gm,"&amp;").replace(/</gm,"&lt;")}function f(r,q,p){return RegExp(q,"m"+(r.cI?"i":"")+(p?"g":""))}function b(r){for(var p=0;p<r.childNodes.length;p++){var q=r.childNodes[p];if(q.nodeName=="CODE"){return q}if(!(q.nodeType==3&&q.nodeValue.match(/\s+/))){break}}}function h(t,s){var p="";for(var r=0;r<t.childNodes.length;r++){if(t.childNodes[r].nodeType==3){var q=t.childNodes[r].nodeValue;if(s){q=q.replace(/\n/g,"")}p+=q}else{if(t.childNodes[r].nodeName=="BR"){p+="\n"}else{p+=h(t.childNodes[r])}}}if(/MSIE [678]/.test(navigator.userAgent)){p=p.replace(/\r/g,"\n")}return p}function a(s){var r=s.className.split(/\s+/);r=r.concat(s.parentNode.className.split(/\s+/));for(var q=0;q<r.length;q++){var p=r[q].replace(/^language-/,"");if(e[p]){return p}}}function c(q){var p=[];(function(s,t){for(var r=0;r<s.childNodes.length;r++){if(s.childNodes[r].nodeType==3){t+=s.childNodes[r].nodeValue.length}else{if(s.childNodes[r].nodeName=="BR"){t+=1}else{if(s.childNodes[r].nodeType==1){p.push({event:"start",offset:t,node:s.childNodes[r]});t=arguments.callee(s.childNodes[r],t);p.push({event:"stop",offset:t,node:s.childNodes[r]})}}}}return t})(q,0);return p}function k(y,w,x){var q=0;var z="";var s=[];function u(){if(y.length&&w.length){if(y[0].offset!=w[0].offset){return(y[0].offset<w[0].offset)?y:w}else{return w[0].event=="start"?y:w}}else{return y.length?y:w}}function t(D){var A="<"+D.nodeName.toLowerCase();for(var B=0;B<D.attributes.length;B++){var C=D.attributes[B];A+=" "+C.nodeName.toLowerCase();if(C.value!==undefined&&C.value!==false&&C.value!==null){A+='="'+m(C.value)+'"'}}return A+">"}while(y.length||w.length){var v=u().splice(0,1)[0];z+=m(x.substr(q,v.offset-q));q=v.offset;if(v.event=="start"){z+=t(v.node);s.push(v.node)}else{if(v.event=="stop"){var p,r=s.length;do{r--;p=s[r];z+=("</"+p.nodeName.toLowerCase()+">")}while(p!=v.node);s.splice(r,1);while(r<s.length){z+=t(s[r]);r++}}}}return z+m(x.substr(q))}function j(){function q(x,y,v){if(x.compiled){return}var u;var s=[];if(x.k){x.lR=f(y,x.l||hljs.IR,true);for(var w in x.k){if(!x.k.hasOwnProperty(w)){continue}if(x.k[w] instanceof Object){u=x.k[w]}else{u=x.k;w="keyword"}for(var r in u){if(!u.hasOwnProperty(r)){continue}x.k[r]=[w,u[r]];s.push(r)}}}if(!v){if(x.bWK){x.b="\\b("+s.join("|")+")\\s"}x.bR=f(y,x.b?x.b:"\\B|\\b");if(!x.e&&!x.eW){x.e="\\B|\\b"}if(x.e){x.eR=f(y,x.e)}}if(x.i){x.iR=f(y,x.i)}if(x.r===undefined){x.r=1}if(!x.c){x.c=[]}x.compiled=true;for(var t=0;t<x.c.length;t++){if(x.c[t]=="self"){x.c[t]=x}q(x.c[t],y,false)}if(x.starts){q(x.starts,y,false)}}for(var p in e){if(!e.hasOwnProperty(p)){continue}q(e[p].dM,e[p],true)}}function d(B,C){if(!j.called){j();j.called=true}function q(r,M){for(var L=0;L<M.c.length;L++){if((M.c[L].bR.exec(r)||[null])[0]==r){return M.c[L]}}}function v(L,r){if(D[L].e&&D[L].eR.test(r)){return 1}if(D[L].eW){var M=v(L-1,r);return M?M+1:0}return 0}function w(r,L){return L.i&&L.iR.test(r)}function K(N,O){var M=[];for(var L=0;L<N.c.length;L++){M.push(N.c[L].b)}var r=D.length-1;do{if(D[r].e){M.push(D[r].e)}r--}while(D[r+1].eW);if(N.i){M.push(N.i)}return f(O,M.join("|"),true)}function p(M,L){var N=D[D.length-1];if(!N.t){N.t=K(N,E)}N.t.lastIndex=L;var r=N.t.exec(M);return r?[M.substr(L,r.index-L),r[0],false]:[M.substr(L),"",true]}function z(N,r){var L=E.cI?r[0].toLowerCase():r[0];var M=N.k[L];if(M&&M instanceof Array){return M}return false}function F(L,P){L=m(L);if(!P.k){return L}var r="";var O=0;P.lR.lastIndex=0;var M=P.lR.exec(L);while(M){r+=L.substr(O,M.index-O);var N=z(P,M);if(N){x+=N[1];r+='<span class="'+N[0]+'">'+M[0]+"</span>"}else{r+=M[0]}O=P.lR.lastIndex;M=P.lR.exec(L)}return r+L.substr(O,L.length-O)}function J(L,M){if(M.sL&&e[M.sL]){var r=d(M.sL,L);x+=r.keyword_count;return r.value}else{return F(L,M)}}function I(M,r){var L=M.cN?'<span class="'+M.cN+'">':"";if(M.rB){y+=L;M.buffer=""}else{if(M.eB){y+=m(r)+L;M.buffer=""}else{y+=L;M.buffer=r}}D.push(M);A+=M.r}function G(N,M,Q){var R=D[D.length-1];if(Q){y+=J(R.buffer+N,R);return false}var P=q(M,R);if(P){y+=J(R.buffer+N,R);I(P,M);return P.rB}var L=v(D.length-1,M);if(L){var O=R.cN?"</span>":"";if(R.rE){y+=J(R.buffer+N,R)+O}else{if(R.eE){y+=J(R.buffer+N,R)+O+m(M)}else{y+=J(R.buffer+N+M,R)+O}}while(L>1){O=D[D.length-2].cN?"</span>":"";y+=O;L--;D.length--}var r=D[D.length-1];D.length--;D[D.length-1].buffer="";if(r.starts){I(r.starts,"")}return R.rE}if(w(M,R)){throw"Illegal"}}var E=e[B];var D=[E.dM];var A=0;var x=0;var y="";try{var s,u=0;E.dM.buffer="";do{s=p(C,u);var t=G(s[0],s[1],s[2]);u+=s[0].length;if(!t){u+=s[1].length}}while(!s[2]);if(D.length>1){throw"Illegal"}return{r:A,keyword_count:x,value:y}}catch(H){if(H=="Illegal"){return{r:0,keyword_count:0,value:m(C)}}else{throw H}}}function g(t){var p={keyword_count:0,r:0,value:m(t)};var r=p;for(var q in e){if(!e.hasOwnProperty(q)){continue}var s=d(q,t);s.language=q;if(s.keyword_count+s.r>r.keyword_count+r.r){r=s}if(s.keyword_count+s.r>p.keyword_count+p.r){r=p;p=s}}if(r.language){p.second_best=r}return p}function i(r,q,p){if(q){r=r.replace(/^((<[^>]+>|\t)+)/gm,function(t,w,v,u){return w.replace(/\t/g,q)})}if(p){r=r.replace(/\n/g,"<br>")}return r}function n(t,w,r){var x=h(t,r);var v=a(t);var y,s;if(v){y=d(v,x)}else{return}var q=c(t);if(q.length){s=document.createElement("pre");s.innerHTML=y.value;y.value=k(q,c(s),x)}y.value=i(y.value,w,r);var u=t.className;if(!u.match("(\\s|^)(language-)?"+v+"(\\s|$)")){u=u?(u+" "+v):v}if(/MSIE [678]/.test(navigator.userAgent)&&t.tagName=="CODE"&&t.parentNode.tagName=="PRE"){s=t.parentNode;var p=document.createElement("div");p.innerHTML="<pre><code>"+y.value+"</code></pre>";t=p.firstChild.firstChild;p.firstChild.cN=s.cN;s.parentNode.replaceChild(p.firstChild,s)}else{t.innerHTML=y.value}t.className=u;t.result={language:v,kw:y.keyword_count,re:y.r};if(y.second_best){t.second_best={language:y.second_best.language,kw:y.second_best.keyword_count,re:y.second_best.r}}}function o(){if(o.called){return}o.called=true;var r=document.getElementsByTagName("pre");for(var p=0;p<r.length;p++){var q=b(r[p]);if(q){n(q,hljs.tabReplace)}}}function l(){if(window.addEventListener){window.addEventListener("DOMContentLoaded",o,false);window.addEventListener("load",o,false)}else{if(window.attachEvent){window.attachEvent("onload",o)}else{window.onload=o}}}var e={};this.LANGUAGES=e;this.highlight=d;this.highlightAuto=g;this.fixMarkup=i;this.highlightBlock=n;this.initHighlighting=o;this.initHighlightingOnLoad=l;this.IR="[a-zA-Z][a-zA-Z0-9_]*";this.UIR="[a-zA-Z_][a-zA-Z0-9_]*";this.NR="\\b\\d+(\\.\\d+)?";this.CNR="\\b(0[xX][a-fA-F0-9]+|(\\d+(\\.\\d*)?|\\.\\d+)([eE][-+]?\\d+)?)";this.BNR="\\b(0b[01]+)";this.RSR="!|!=|!==|%|%=|&|&&|&=|\\*|\\*=|\\+|\\+=|,|\\.|-|-=|/|/=|:|;|<|<<|<<=|<=|=|==|===|>|>=|>>|>>=|>>>|>>>=|\\?|\\[|\\{|\\(|\\^|\\^=|\\||\\|=|\\|\\||~";this.ER="(?![\\s\\S])";this.BE={b:"\\\\.",r:0};this.ASM={cN:"string",b:"'",e:"'",i:"\\n",c:[this.BE],r:0};this.QSM={cN:"string",b:'"',e:'"',i:"\\n",c:[this.BE],r:0};this.CLCM={cN:"comment",b:"//",e:"$"};this.CBLCLM={cN:"comment",b:"/\\*",e:"\\*/"};this.HCM={cN:"comment",b:"#",e:"$"};this.NM={cN:"number",b:this.NR,r:0};this.CNM={cN:"number",b:this.CNR,r:0};this.BNM={cN:"number",b:this.BNR,r:0};this.inherit=function(r,s){var p={};for(var q in r){p[q]=r[q]}if(s){for(var q in s){p[q]=s[q]}}return p}}();hljs.LANGUAGES.cpp=function(){var a={keyword:{"false":1,"int":1,"float":1,"while":1,"private":1,"char":1,"catch":1,"export":1,virtual:1,operator:2,sizeof:2,dynamic_cast:2,typedef:2,const_cast:2,"const":1,struct:1,"for":1,static_cast:2,union:1,namespace:1,unsigned:1,"long":1,"throw":1,"volatile":2,"static":1,"protected":1,bool:1,template:1,mutable:1,"if":1,"public":1,friend:2,"do":1,"return":1,"goto":1,auto:1,"void":2,"enum":1,"else":1,"break":1,"new":1,extern:1,using:1,"true":1,"class":1,asm:1,"case":1,typeid:1,"short":1,reinterpret_cast:2,"default":1,"double":1,register:1,explicit:1,signed:1,typename:1,"try":1,"this":1,"switch":1,"continue":1,wchar_t:1,inline:1,"delete":1,alignof:1,char16_t:1,char32_t:1,constexpr:1,decltype:1,noexcept:1,nullptr:1,static_assert:1,thread_local:1,restrict:1,_Bool:1,complex:1},built_in:{std:1,string:1,cin:1,cout:1,cerr:1,clog:1,stringstream:1,istringstream:1,ostringstream:1,auto_ptr:1,deque:1,list:1,queue:1,stack:1,vector:1,map:1,set:1,bitset:1,multiset:1,multimap:1,unordered_set:1,unordered_map:1,unordered_multiset:1,unordered_multimap:1,array:1,shared_ptr:1}};return{dM:{k:a,i:"</",c:[hljs.CLCM,hljs.CBLCLM,hljs.QSM,{cN:"string",b:"'\\\\?.",e:"'",i:"."},{cN:"number",b:"\\b(\\d+(\\.\\d*)?|\\.\\d+)(u|U|l|L|ul|UL|f|F)"},hljs.CNM,{cN:"preprocessor",b:"#",e:"$"},{cN:"stl_container",b:"\\b(deque|list|queue|stack|vector|map|set|bitset|multiset|multimap|unordered_map|unordered_set|unordered_multiset|unordered_multimap|array)\\s*<",e:">",k:a,r:10,c:["self"]}]}}}();hljs.LANGUAGES.r={dM:{c:[hljs.HCM,{cN:"number",b:"\\b0[xX][0-9a-fA-F]+[Li]?\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\b\\d+(?:[eE][+\\-]?\\d*)?L\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\b\\d+\\.(?!\\d)(?:i\\b)?",e:hljs.IMMEDIATE_RE,r:1},{cN:"number",b:"\\b\\d+(?:\\.\\d*)?(?:[eE][+\\-]?\\d*)?i?\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\.\\d+(?:[eE][+\\-]?\\d*)?i?\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"keyword",b:"(?:tryCatch|library|setGeneric|setGroupGeneric)\\b",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\.\\.\\.",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\.\\.\\d+(?![\\w.])",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\b(?:function)",e:hljs.IMMEDIATE_RE,r:2},{cN:"keyword",b:"(?:if|in|break|next|repeat|else|for|return|switch|while|try|stop|warning|require|attach|detach|source|setMethod|setClass)\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"literal",b:"(?:NA|NA_integer_|NA_real_|NA_character_|NA_complex_)\\b",e:hljs.IMMEDIATE_RE,r:10},{cN:"literal",b:"(?:NULL|TRUE|FALSE|T|F|Inf|NaN)\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"identifier",b:"[a-zA-Z.][a-zA-Z0-9._]*\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"operator",b:"<\\-(?!\\s*\\d)",e:hljs.IMMEDIATE_RE,r:2},{cN:"operator",b:"\\->|<\\-",e:hljs.IMMEDIATE_RE,r:1},{cN:"operator",b:"%%|~",e:hljs.IMMEDIATE_RE},{cN:"operator",b:">=|<=|==|!=|\\|\\||&&|=|\\+|\\-|\\*|/|\\^|>|<|!|&|\\||\\$|:",e:hljs.IMMEDIATE_RE,r:0},{cN:"operator",b:"%",e:"%",i:"\\n",r:1},{cN:"identifier",b:"`",e:"`",r:0},{cN:"string",b:'"',e:'"',c:[hljs.BE],r:0},{cN:"string",b:"'",e:"'",c:[hljs.BE],r:0},{cN:"paren",b:"[[({\\])}]",e:hljs.IMMEDIATE_RE,r:0}]}};
hljs.initHighlightingOnLoad();
</script>

<!-- MathJax scripts -->
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<style type="text/css">
body, td {
   font-family: sans-serif;
   background-color: white;
   font-size: 13px;
}

body {
  max-width: 800px;
  margin: auto;
  padding: 1em;
  line-height: 20px;
}

tt, code, pre {
   font-family: 'DejaVu Sans Mono', 'Droid Sans Mono', 'Lucida Console', Consolas, Monaco, monospace;
}

h1 {
   font-size:2.2em;
}

h2 {
   font-size:1.8em;
}

h3 {
   font-size:1.4em;
}

h4 {
   font-size:1.0em;
}

h5 {
   font-size:0.9em;
}

h6 {
   font-size:0.8em;
}

a:visited {
   color: rgb(50%, 0%, 50%);
}

pre, img {
  max-width: 100%;
}
pre {
  overflow-x: auto;
}
pre code {
   display: block; padding: 0.5em;
}

code {
  font-size: 92%;
  border: 1px solid #ccc;
}

code[class] {
  background-color: #F8F8F8;
}

table, td, th {
  border: none;
}

blockquote {
   color:#666666;
   margin:0;
   padding-left: 1em;
   border-left: 0.5em #EEE solid;
}

hr {
   height: 0px;
   border-bottom: none;
   border-top-width: thin;
   border-top-style: dotted;
   border-top-color: #999999;
}

@media print {
   * {
      background: transparent !important;
      color: black !important;
      filter:none !important;
      -ms-filter: none !important;
   }

   body {
      font-size:12pt;
      max-width:100%;
   }

   a, a:visited {
      text-decoration: underline;
   }

   hr {
      visibility: hidden;
      page-break-before: always;
   }

   pre, blockquote {
      padding-right: 1em;
      page-break-inside: avoid;
   }

   tr, img {
      page-break-inside: avoid;
   }

   img {
      max-width: 100% !important;
   }

   @page :left {
      margin: 15mm 20mm 15mm 10mm;
   }

   @page :right {
      margin: 15mm 10mm 15mm 20mm;
   }

   p, h2, h3 {
      orphans: 3; widows: 3;
   }

   h2, h3 {
      page-break-after: avoid;
   }
}
</style>



</head>

<body>
<h2>Getting and Cleaning Data Course Project</h2>

<h3>Introduction</h3>

<p>The purpose of this project is to demonstrate the ability to collect, work with, and clean a data set. The goal is to prepare tidy data that can be used for later analysis.  The required submissions are: 1) a tidy data set as described below, 2) a link to a Github repository with a script for performing the analysis, and 3) a code book that describes the variables, the data, and any transformations or work that were performed to clean up the data called CodeBook.md. In addition, a README.md should also be included in the repo with your scripts. This repo explains how all of the scripts work and how they are connected.</p>

<p>The data linked to from the course website represent data collected from the accelerometers from the Samsung Galaxy S smartphone. A full description is available at the site where the data was obtained:</p>

<p><a href="http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones">http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones</a></p>

<p>Here are the data for the project:</p>

<p><a href="https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip">https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip</a></p>

<p>There also is an R script called run_analysis.R that does the following.</p>

<p>1) Merges the training and the test sets to create one data set.
   2) Extracts only the measurements on the mean and standard deviation for each measurement.
   3) Uses descriptive activity names to name the activities in the data set
   4) Appropriately labels the data set with descriptive variable names.
   5) From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject.</p>

<h3>Initial Workspace Preparation</h3>

<p>Remove any old files and clean up workspace</p>

<pre><code class="r">rm(list=ls(all=TRUE))
</code></pre>

<p>Call appropriate libraries for functions</p>

<pre><code class="r">library(data.table)
library(dplyr)
library(knitr)
library(markdown)
</code></pre>

<p>Create working directory if it does not already exist</p>

<pre><code class="r">if (!getwd() == &quot;D:/R_workplace/DataScienceSpecialization/getting_and_cleaning_data/data&quot;)
   { dir.create(&quot;D:/R_workplace/DataScienceSpecialization/getting_and_cleaning_data/data&quot;)
}
</code></pre>

<p>Set working directory and assign it to wd</p>

<pre><code class="r">setwd(&quot;D:/R_workplace/DataScienceSpecialization/getting_and_cleaning_data/data&quot;)
wd &lt;- getwd()
</code></pre>

<h3>Download Data Files and Unzip Files to be Analyzed</h3>

<p>Assign dataset zipfile to a<br/>
Assign url for file location to fileUrl<br/>
Download file using assigned parameters</p>

<pre><code class="r">a &lt;- &quot;Dataset.zip&quot;
fileUrl &lt;- &quot;https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip&quot;
download.file(fileUrl, file.path(wd, a))
</code></pre>

<p>Extract list of all files in the zip file and assign to p<br/>
View files in zip archive</p>

<pre><code class="r">p &lt;- unzip(file.path(wd, a), list=TRUE)
p
</code></pre>

<pre><code>##                                                            Name   Length
## 1                           UCI HAR Dataset/activity_labels.txt       80
## 2                                  UCI HAR Dataset/features.txt    15785
## 3                             UCI HAR Dataset/features_info.txt     2809
## 4                                    UCI HAR Dataset/README.txt     4453
## 5                                         UCI HAR Dataset/test/        0
## 6                        UCI HAR Dataset/test/Inertial Signals/        0
## 7     UCI HAR Dataset/test/Inertial Signals/body_acc_x_test.txt  6041350
## 8     UCI HAR Dataset/test/Inertial Signals/body_acc_y_test.txt  6041350
## 9     UCI HAR Dataset/test/Inertial Signals/body_acc_z_test.txt  6041350
## 10   UCI HAR Dataset/test/Inertial Signals/body_gyro_x_test.txt  6041350
## 11   UCI HAR Dataset/test/Inertial Signals/body_gyro_y_test.txt  6041350
## 12   UCI HAR Dataset/test/Inertial Signals/body_gyro_z_test.txt  6041350
## 13   UCI HAR Dataset/test/Inertial Signals/total_acc_x_test.txt  6041350
## 14   UCI HAR Dataset/test/Inertial Signals/total_acc_y_test.txt  6041350
## 15   UCI HAR Dataset/test/Inertial Signals/total_acc_z_test.txt  6041350
## 16                        UCI HAR Dataset/test/subject_test.txt     7934
## 17                              UCI HAR Dataset/test/X_test.txt 26458166
## 18                              UCI HAR Dataset/test/y_test.txt     5894
## 19                                       UCI HAR Dataset/train/        0
## 20                      UCI HAR Dataset/train/Inertial Signals/        0
## 21  UCI HAR Dataset/train/Inertial Signals/body_acc_x_train.txt 15071600
## 22  UCI HAR Dataset/train/Inertial Signals/body_acc_y_train.txt 15071600
## 23  UCI HAR Dataset/train/Inertial Signals/body_acc_z_train.txt 15071600
## 24 UCI HAR Dataset/train/Inertial Signals/body_gyro_x_train.txt 15071600
## 25 UCI HAR Dataset/train/Inertial Signals/body_gyro_y_train.txt 15071600
## 26 UCI HAR Dataset/train/Inertial Signals/body_gyro_z_train.txt 15071600
## 27 UCI HAR Dataset/train/Inertial Signals/total_acc_x_train.txt 15071600
## 28 UCI HAR Dataset/train/Inertial Signals/total_acc_y_train.txt 15071600
## 29 UCI HAR Dataset/train/Inertial Signals/total_acc_z_train.txt 15071600
## 30                      UCI HAR Dataset/train/subject_train.txt    20152
## 31                            UCI HAR Dataset/train/X_train.txt 66006256
## 32                            UCI HAR Dataset/train/y_train.txt    14704
##                   Date
## 1  2012-10-10 15:55:00
## 2  2012-10-11 13:41:00
## 3  2012-10-15 15:44:00
## 4  2012-12-10 10:38:00
## 5  2012-11-29 17:01:00
## 6  2012-11-29 17:01:00
## 7  2012-11-29 15:08:00
## 8  2012-11-29 15:08:00
## 9  2012-11-29 15:08:00
## 10 2012-11-29 15:09:00
## 11 2012-11-29 15:09:00
## 12 2012-11-29 15:09:00
## 13 2012-11-29 15:08:00
## 14 2012-11-29 15:09:00
## 15 2012-11-29 15:09:00
## 16 2012-11-29 15:09:00
## 17 2012-11-29 15:25:00
## 18 2012-11-29 15:09:00
## 19 2012-11-29 17:01:00
## 20 2012-11-29 17:01:00
## 21 2012-11-29 15:08:00
## 22 2012-11-29 15:08:00
## 23 2012-11-29 15:08:00
## 24 2012-11-29 15:09:00
## 25 2012-11-29 15:09:00
## 26 2012-11-29 15:09:00
## 27 2012-11-29 15:08:00
## 28 2012-11-29 15:08:00
## 29 2012-11-29 15:08:00
## 30 2012-11-29 15:09:00
## 31 2012-11-29 15:25:00
## 32 2012-11-29 15:09:00
</code></pre>

<p>Remove any files with &ldquo;Inertial&rdquo;&ldquo; in name as they are not part of the data analysis<br/>
View file names of files to be extracted</p>

<pre><code class="r">p &lt;- p[grep(&quot;Inertial&quot;, p$Name, invert=TRUE),1]
p
</code></pre>

<pre><code>##  [1] &quot;UCI HAR Dataset/activity_labels.txt&quot;    
##  [2] &quot;UCI HAR Dataset/features.txt&quot;           
##  [3] &quot;UCI HAR Dataset/features_info.txt&quot;      
##  [4] &quot;UCI HAR Dataset/README.txt&quot;             
##  [5] &quot;UCI HAR Dataset/test/&quot;                  
##  [6] &quot;UCI HAR Dataset/test/subject_test.txt&quot;  
##  [7] &quot;UCI HAR Dataset/test/X_test.txt&quot;        
##  [8] &quot;UCI HAR Dataset/test/y_test.txt&quot;        
##  [9] &quot;UCI HAR Dataset/train/&quot;                 
## [10] &quot;UCI HAR Dataset/train/subject_train.txt&quot;
## [11] &quot;UCI HAR Dataset/train/X_train.txt&quot;      
## [12] &quot;UCI HAR Dataset/train/y_train.txt&quot;
</code></pre>

<p>Unzip only files that are necessary for the data analysis project<br/>
Collapse folder structure so that all files are in working directory</p>

<pre><code class="r">unzip(file.path(wd, a),files= p, junkpaths=TRUE)
</code></pre>

<p>Once files are unzipped then view README.txt in order to understand construction of data files and how they can be combined into a dataset to be analyzed</p>

<h3>Read Data Files into Workspace and Examine Characteristics</h3>

<p>Read test and train .txt data files into data tables in working directory<br/>
Examine size of data tables to get first indication of their dimensions</p>

<pre><code class="r">test_data  &lt;- fread(file.path(wd, &quot;X_test.txt&quot;))
train_data  &lt;- fread(file.path(wd, &quot;X_train.txt&quot;))
dim(test_data)
</code></pre>

<pre><code>## [1] 2947  561
</code></pre>

<pre><code class="r">dim(train_data)
</code></pre>

<pre><code>## [1] 7352  561
</code></pre>

<p>Examine names of columns in test and train files to determine if they are similar</p>

<pre><code class="r">names(test_data) == names(train_data)
</code></pre>

<pre><code>##   [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
##  [15] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
##  [29] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
##  [43] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
##  [57] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
##  [71] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
##  [85] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
##  [99] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
## [113] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
## [127] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
## [141] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
## [155] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
## [169] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
## [183] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
## [197] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
## [211] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
## [225] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
## [239] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
## [253] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
## [267] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
## [281] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
## [295] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
## [309] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
## [323] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
## [337] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
## [351] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
## [365] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
## [379] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
## [393] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
## [407] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
## [421] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
## [435] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
## [449] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
## [463] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
## [477] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
## [491] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
## [505] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
## [519] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
## [533] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
## [547] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
## [561] TRUE
</code></pre>

<p>Read test and train activity label .txt files into data tables in working directory<br/>
Examine structure of test and train activity label data tables<br/>
Determine count of label activities that exist in both test and train label data tables</p>

<pre><code class="r">test_label &lt;- fread(file.path(wd, &quot;y_test.txt&quot;))
train_label &lt;- fread(file.path(wd, &quot;y_train.txt&quot;))
str(test_label)
</code></pre>

<pre><code>## Classes &#39;data.table&#39; and &#39;data.frame&#39;:   2947 obs. of  1 variable:
##  $ V1: int  5 5 5 5 5 5 5 5 5 5 ...
##  - attr(*, &quot;.internal.selfref&quot;)=&lt;externalptr&gt;
</code></pre>

<pre><code class="r">str(train_label)
</code></pre>

<pre><code>## Classes &#39;data.table&#39; and &#39;data.frame&#39;:   7352 obs. of  1 variable:
##  $ V1: int  5 5 5 5 5 5 5 5 5 5 ...
##  - attr(*, &quot;.internal.selfref&quot;)=&lt;externalptr&gt;
</code></pre>

<pre><code class="r">table(test_label)
</code></pre>

<pre><code>## test_label
##   1   2   3   4   5   6 
## 496 471 420 491 532 537
</code></pre>

<pre><code class="r">table(train_label)
</code></pre>

<pre><code>## train_label
##    1    2    3    4    5    6 
## 1226 1073  986 1286 1374 1407
</code></pre>

<p>Read features .txt file into data table so column names can be attached to test and train data tables and examine</p>

<pre><code class="r">features &lt;- fread(file.path(wd, &quot;features.txt&quot;))
head(features)
</code></pre>

<pre><code>##    V1                V2
## 1:  1 tBodyAcc-mean()-X
## 2:  2 tBodyAcc-mean()-Y
## 3:  3 tBodyAcc-mean()-Z
## 4:  4  tBodyAcc-std()-X
## 5:  5  tBodyAcc-std()-Y
## 6:  6  tBodyAcc-std()-Z
</code></pre>

<p>Read activity labels .txt files into data table and then examine so we know what types of activities are being evaluated </p>

<pre><code class="r">activities &lt;- fread(file.path(wd, &quot;activity_labels.txt&quot;))
head(activities)
</code></pre>

<pre><code>##    V1                 V2
## 1:  1            WALKING
## 2:  2   WALKING_UPSTAIRS
## 3:  3 WALKING_DOWNSTAIRS
## 4:  4            SITTING
## 5:  5           STANDING
## 6:  6             LAYING
</code></pre>

<p>Examine structure of features and activities data tables</p>

<pre><code class="r">str(features)
</code></pre>

<pre><code>## Classes &#39;data.table&#39; and &#39;data.frame&#39;:   561 obs. of  2 variables:
##  $ V1: int  1 2 3 4 5 6 7 8 9 10 ...
##  $ V2: chr  &quot;tBodyAcc-mean()-X&quot; &quot;tBodyAcc-mean()-Y&quot; &quot;tBodyAcc-mean()-Z&quot; &quot;tBodyAcc-std()-X&quot; ...
##  - attr(*, &quot;.internal.selfref&quot;)=&lt;externalptr&gt;
</code></pre>

<pre><code class="r">str(activities)
</code></pre>

<pre><code>## Classes &#39;data.table&#39; and &#39;data.frame&#39;:   6 obs. of  2 variables:
##  $ V1: int  1 2 3 4 5 6
##  $ V2: chr  &quot;WALKING&quot; &quot;WALKING_UPSTAIRS&quot; &quot;WALKING_DOWNSTAIRS&quot; &quot;SITTING&quot; ...
##  - attr(*, &quot;.internal.selfref&quot;)=&lt;externalptr&gt;
</code></pre>

<p>Read subject test and train .txt files into data tables so they can be used to specify which subjects performed which activity and the respective captured data<br/>
Examine the structure of the test and train subject data tables</p>

<pre><code class="r">subject_test &lt;- fread(file.path(wd, &quot;subject_test.txt&quot;))
subject_train &lt;- fread(file.path(wd, &quot;subject_train.txt&quot;))
str(subject_test)
</code></pre>

<pre><code>## Classes &#39;data.table&#39; and &#39;data.frame&#39;:   2947 obs. of  1 variable:
##  $ V1: int  2 2 2 2 2 2 2 2 2 2 ...
##  - attr(*, &quot;.internal.selfref&quot;)=&lt;externalptr&gt;
</code></pre>

<pre><code class="r">str(subject_train)
</code></pre>

<pre><code>## Classes &#39;data.table&#39; and &#39;data.frame&#39;:   7352 obs. of  1 variable:
##  $ V1: int  1 1 1 1 1 1 1 1 1 1 ...
##  - attr(*, &quot;.internal.selfref&quot;)=&lt;externalptr&gt;
</code></pre>

<h3>Merge Data Sets</h3>

<p>Now that all data sets have been examined and the README and features_info text files have been read, it is time to begin to merge the data sets as per the instructions<br/>
Use rbind to row bind the respective train and test data sets for the main data, the activity label data, and the subject data<br/>
Examine the dimensions of the combined main data set, the combined activity label data set, and the combined subject data set</p>

<pre><code class="r">data_all &lt;- rbind(train_data, test_data)
label_all &lt;- rbind(train_label, test_label)
subject_all &lt;- rbind(subject_train, subject_test)
dim(data_all)
</code></pre>

<pre><code>## [1] 10299   561
</code></pre>

<pre><code class="r">dim(label_all)
</code></pre>

<pre><code>## [1] 10299     1
</code></pre>

<pre><code class="r">dim(subject_all)
</code></pre>

<pre><code>## [1] 10299     1
</code></pre>

<h3>Extract Measurements for Mean and Standard Deviation Only</h3>

<p>Now extract only measurements on the mean and standard deviation for each measurement  </p>

<p>Step 1 is to determine which columns have mean [mean()] and standard deviation [std()] in them<br/>
Only variables with the mean or standard deviation of the entire variable are examined (this results in only including variables which have mean() or std() at the end of the variable name)</p>

<pre><code class="r">data_col &lt;- features[grep(&quot;mean\\(\\)|std\\(\\)&quot;, V2)]
</code></pre>

<p>Step 2 is to extract the first column from the resulting data table and append &quot;v&rdquo; to the front of each variable in order to create a link variable so that we can map the extracted features to the main data column names</p>

<pre><code class="r">coll &lt;- data_col[[1]]
coll &lt;- paste0(&quot;V&quot;, coll)
head(coll)
</code></pre>

<pre><code>## [1] &quot;V1&quot; &quot;V2&quot; &quot;V3&quot; &quot;V4&quot; &quot;V5&quot; &quot;V6&quot;
</code></pre>

<p>Step 3 is to use the resultant link vector for the extracted features with mean and standard deviation measurements to subset the main data table into the columns that are required for the analysis</p>

<pre><code class="r">data_all &lt;- data_all[,coll, with= FALSE]
</code></pre>

<p>Check that the vector of link variables matches the column names of the extracted main data set to ensure that the relative ordering of the variables is the same</p>

<pre><code class="r">names(data_all) == coll
</code></pre>

<pre><code>##  [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
## [15] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
## [29] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
## [43] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
## [57] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
</code></pre>

<h3>Appropriately Label the Data Set with Descriptive Variable Names</h3>

<p>Next replace the variable names in the columns with the more decriptive feature labels also replace the column names in label_all, activities, and subject_all data tables so that when they are combined they will have the correct column names</p>

<pre><code class="r">setnames(data_all, names(data_all), data_col$V2)
setnames(label_all, &quot;V1&quot;, &quot;Link&quot;)
setnames(activities, &quot;V1&quot;, &quot;Link&quot;)
setnames(activities, &quot;V2&quot;, &quot;Activities&quot;)
setnames(subject_all, &quot;V1&quot;, &quot;Subject&quot;)
</code></pre>

<p>Combine the subject data table with the activity label data table and the extracted main data data table</p>

<pre><code class="r">data_all &lt;- cbind(subject_all, label_all, data_all)
</code></pre>

<p>At this point the column names are still fairly cryptic and since we desire easily understandable names, we replace the abbreviations with the actual word in the data table columns - this results in descriptive column names for the respective measurements that can be easily read and understood</p>

<pre><code class="r">names(data_all) &lt;- gsub(&quot;^t&quot;, &quot;time_&quot;, names(data_all))
names(data_all) &lt;- gsub(&quot;^f&quot;, &quot;frequency_&quot;, names(data_all))
names(data_all) &lt;- gsub(&quot;Acc&quot;, &quot;_Acceleration&quot;, names(data_all))
names(data_all) &lt;- gsub(&quot;Gyro&quot;, &quot;_Gyroscope&quot;, names(data_all))
names(data_all) &lt;- gsub(&quot;Jerk&quot;, &quot;_Jerk&quot;, names(data_all))
names(data_all) &lt;- gsub(&quot;Mag&quot;, &quot;_Magnitude&quot;, names(data_all))
names(data_all) &lt;- gsub(&quot;BodyBody&quot;, &quot;Body_Body&quot;, names(data_all))
</code></pre>

<h3>Use Descriptive Activity Names to Name the Activities in the Data Set</h3>

<p>Next merge the main data table with the activities data table so the activities in the main data table have desctiptive names and are readily understandable<br/>
Remove the &ldquo;Link&rdquo; variable that was used to merge the data tables</p>

<pre><code class="r">data_all &lt;- merge(data_all, activities, &quot;Link&quot;)
data_all$Link &lt;- NULL
</code></pre>

<p>Set column order so that Subject is in the first column and Activites are in the second column and the additional columns follow in their respective order</p>

<pre><code class="r">setcolorder(data_all, c(&quot;Subject&quot;, &quot;Activities&quot;, colnames(data_all)[!(colnames(data_all) 
    %in% c(&quot;Subject&quot;, &quot;Activities&quot;))]))
</code></pre>

<h3>Create Tidy Data Set from the Aggregated Data Table</h3>

<p>Designate the columns for Subject and Activities are factors to facilitate additional analysis</p>

<pre><code class="r">data_all$Subject &lt;- factor(data_all$Subject)
data_all$Activities &lt;- factor(data_all$Activities)
</code></pre>

<p>Create vector of all measurement variables to facilitate the translation from a wide data table to a narrow data table with all measurements in one column using melt in the next data step<br/>
Create a narrow data table with the types of measurement for each Subject and Activities combination in one column and the resulting value of the measurements in another column<br/>
This is the long form of tidy data as mentioned in the rubric as either long or wide form is acceptable</p>

<pre><code class="r">mysubset &lt;- colnames(data_all)[!(colnames(data_all) 
                                  %in% c(&quot;Subject&quot;, &quot;Activities&quot;))]
data_all_narrow &lt;- melt(data_all, c(&quot;Subject&quot;, &quot;Activities&quot;), mysubset, variable.name= 
    &quot;Measurement&quot;)
</code></pre>

<h3>Creates a Second, Independent Tidy Data Set with the Average of Each Variable for Each Activity and Each Subject</h3>

<p>Complete the second, independent tidy data set in the data table by grouping the data by each subject and each activity and calculating the respective average for each grouped variable. This is the long form of tidy data as mentioned in the rubric as either long or wide form is acceptable.<br/>
The principles of tidy data are:  </p>

<ol>
<li>Each variable forms a column.<br/></li>
<li>Each observation forms a row.<br/></li>
<li>Each type of observational unit forms a table.<br/>
See Wickham, Hadley, &ldquo;Tidy Data&rdquo;, Journal of Statistical Software, MMMMMM YYYY, Volume VV, Issue II. <a href="http://www.jstatsoft.org/">http://www.jstatsoft.org/</a></li>
</ol>

<pre><code class="r">tidy_data &lt;- data_all_narrow %&gt;% group_by(Subject, Activities, Measurement) %&gt;% 
    summarize(Average= mean(value))
</code></pre>

<p>Examine resulting tidy data set</p>

<pre><code class="r">head(tidy_data,n=15)
</code></pre>

<pre><code>## Source: local data frame [15 x 4]
## Groups: Subject, Activities [1]
## 
##    Subject Activities                          Measurement      Average
##     &lt;fctr&gt;     &lt;fctr&gt;                               &lt;fctr&gt;        &lt;dbl&gt;
## 1        1     LAYING      time_Body_Acceleration-mean()-X  0.221598244
## 2        1     LAYING      time_Body_Acceleration-mean()-Y -0.040513953
## 3        1     LAYING      time_Body_Acceleration-mean()-Z -0.113203554
## 4        1     LAYING       time_Body_Acceleration-std()-X -0.928056469
## 5        1     LAYING       time_Body_Acceleration-std()-Y -0.836827406
## 6        1     LAYING       time_Body_Acceleration-std()-Z -0.826061402
## 7        1     LAYING   time_Gravity_Acceleration-mean()-X -0.248881798
## 8        1     LAYING   time_Gravity_Acceleration-mean()-Y  0.705549773
## 9        1     LAYING   time_Gravity_Acceleration-mean()-Z  0.445817720
## 10       1     LAYING    time_Gravity_Acceleration-std()-X -0.896830018
## 11       1     LAYING    time_Gravity_Acceleration-std()-Y -0.907720007
## 12       1     LAYING    time_Gravity_Acceleration-std()-Z -0.852366290
## 13       1     LAYING time_Body_Acceleration_Jerk-mean()-X  0.081086534
## 14       1     LAYING time_Body_Acceleration_Jerk-mean()-Y  0.003838204
## 15       1     LAYING time_Body_Acceleration_Jerk-mean()-Z  0.010834236
</code></pre>

<p>Write tidy_data to .txt file</p>

<pre><code class="r">write.table(tidy_data, &quot;HumanActivityRecognitionUsingSmartphones.txt&quot;)
</code></pre>

<p>read HumanActivityRecognitionUsingSmartphones.txt</p>

<pre><code class="r">final_tidy_data &lt;- read.table(&quot;HumanActivityRecognitionUsingSmartphones.txt&quot;, header= TRUE)
View(final_tidy_data)
</code></pre>

<p>Create Codebook.md</p>

<pre><code class="r">knit(&quot;Codebook.Rmd&quot;, encoding=&quot;ISO8859-1&quot;)
</code></pre>

<pre><code>## 
## 
## processing file: Codebook.Rmd
</code></pre>

<pre><code>## 
  |                                                                       
  |                                                                 |   0%
  |                                                                       
  |....                                                             |   6%
##   ordinary text without R code
## 
## 
  |                                                                       
  |........                                                         |  12%
## label: unnamed-chunk-33
## 
  |                                                                       
  |...........                                                      |  18%
##   ordinary text without R code
## 
## 
  |                                                                       
  |...............                                                  |  24%
## label: unnamed-chunk-34
## 
  |                                                                       
  |...................                                              |  29%
##   ordinary text without R code
## 
## 
  |                                                                       
  |.......................                                          |  35%
## label: unnamed-chunk-35
## 
  |                                                                       
  |...........................                                      |  41%
##   ordinary text without R code
## 
## 
  |                                                                       
  |...............................                                  |  47%
## label: unnamed-chunk-36
## 
  |                                                                       
  |..................................                               |  53%
##   ordinary text without R code
## 
## 
  |                                                                       
  |......................................                           |  59%
## label: unnamed-chunk-37
## 
  |                                                                       
  |..........................................                       |  65%
##   ordinary text without R code
## 
## 
  |                                                                       
  |..............................................                   |  71%
## label: unnamed-chunk-38
## 
  |                                                                       
  |..................................................               |  76%
##   ordinary text without R code
## 
## 
  |                                                                       
  |......................................................           |  82%
## label: unnamed-chunk-39
## 
  |                                                                       
  |.........................................................        |  88%
##   ordinary text without R code
## 
## 
  |                                                                       
  |.............................................................    |  94%
## label: unnamed-chunk-40
## 
  |                                                                       
  |.................................................................| 100%
##   ordinary text without R code
</code></pre>

<pre><code>## output file: Codebook.md
</code></pre>

<pre><code>## [1] &quot;Codebook.md&quot;
</code></pre>

<pre><code class="r">markdownToHTML(&quot;Codebook.md&quot;, &quot;Codebook.html&quot;)
</code></pre>

</body>

</html>
